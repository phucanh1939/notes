## Fallacies and Pitfalls (Misconceptions)

### *Expecting the improvement of one aspect of a computer to increase overall performance by an amount proportional to the size of the improvement*

This refers to the incorrect assumption that improvement of one aspect x times wil increase overall performance x times.

Ex. Suppose a program runs in 100 seconds on a computer, with multiply operations responsible for 80 seconds of this time. How much do I have to improve the speed of multiplication if I want my program to run five times faster?

The wrong answer is: We need to improve multiplication operation performance 5 times faster

The right answer is: There is no amount by which we can enhance-multiply to achieve a five times increase in performance, if multiply accounts for only 80% of the workload.

The reason is: Five time faster means execution time = 20s = execution time of other things that NOT multiply operation, it means multiply operations execution time must be 0s to achive the total 20s execution time which impossible.


### *Computers at low utilization use little power*

The fallacy that computers at low utilization use little power refers to the incorrect assumption that when a server or computer system is lightly loaded (e.g., only handling 10% of its maximum workload), it consumes a proportionally small amount of energy, like 10% of peak power. In reality, computers and servers are not very energy-efficient at low utilization, and they still consume a substantial amount of power, even when the workload is minimal.

The reason this matters is that server workloads vary greatly, and systems are rarely operating at full capacity (100%) most of the time. As mentioned in the quote, Google’s warehouse-scale computers are usually only between 10% and 50% utilized, with full utilization (100%) occurring less than 1% of the time. Yet, these systems still consume a large fraction of their peak power even when they are only handling light workloads.

### *Designing for performance and designing for energy efficiency are unrelated goals*

The misconception that focusing on maximizing performance has no relation to improving energy efficiency. In reality, these two goals are often closely linked.

Since energy is power over time, making an optimization that speeds up a task can save energy, even if it temporarily increases power consumption. The key is that a faster completion time reduces the total energy usage of the system because the rest of the system (CPU, memory, storage, etc.) consumes energy while waiting for the task to finish.

For example, if a program runs inefficiently and takes more time to complete, the entire system stays active longer, draining more energy overall. By optimizing the program—whether through hardware or software changes—even if the optimized portion uses slightly more power, the time savings means that the system as a whole consumes less energy overall because it spends less time running.

This relationship shows that performance improvements often lead to energy savings, especially in scenarios where reducing time spent on computations minimizes total system energy usage. Thus, the goals of performance and energy efficiency are complementary, not contradictory, because improving performance can also reduce energy usage across a system. This concept is essential for designing modern, energy-efficient computing systems.

## *Using a subset of the performance equation as a performance metric*

Using only a subset (1 or 2 factors) of the performance equation (include 3 factors: Instruction count, CPI and clock rate) as performance metric leading to a incorrect result

Ex. Can NOT use only instruction count of the program to compare the performance of 2 CPU (since the CPU with more instruction count may have lower CPI and clock cycle time)

**ALWAYS USE EXECUTION TIME INSTEAD OF SUBSET OF 3 FACTORS**
